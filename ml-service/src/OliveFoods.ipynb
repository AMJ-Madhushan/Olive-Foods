{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rO4b1ClQ_Fr_",
        "outputId": "87c2f802-af74-4989-b484-7709ffa26f7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üîó GOOGLE COLAB DETECTED\n",
            "======================================================================\n",
            "\n",
            "üìÅ Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úì Google Drive mounted successfully!\n",
            "‚úì Working base path (My Drive): /content/drive/MyDrive\n",
            "\n",
            "======================================================================\n",
            "üçΩ  OLIVE FOODS - ML MODEL TRAINING\n",
            "======================================================================\n",
            "\n",
            "Health-Based Food Recommendation System\n",
            "Training machine learning model for personalized food recommendations\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "üìä LOADING DATASET\n",
            "======================================================================\n",
            "‚úì Dataset loaded successfully!\n",
            "  - Path: /content/drive/MyDrive/food_health_dataset.csv\n",
            "  - Shape: (5000, 12)\n",
            "  - Food items: 5000\n",
            "\n",
            "üìã First few rows:\n",
            "   food_id             food_name         category  calories  protein  \\\n",
            "0        1      Greek Veggie Mix  Salads & Greens       150       12   \n",
            "1        2        Grilled Quinoa  Salads & Greens       190       18   \n",
            "2        3  Avocado Super Greens  Salads & Greens       150       10   \n",
            "3        4         Fresh Spinach  Salads & Greens       171       20   \n",
            "4        5  Herbed Chicken Salad  Salads & Greens       150        9   \n",
            "\n",
            "   carbohydrates  diabetes_score  hypertension_score  heart_disease_score  \\\n",
            "0             10               9                  10                   10   \n",
            "1             26               7                   9                   10   \n",
            "2             11               9                  10                   10   \n",
            "3             14               8                   9                   10   \n",
            "4             20               7                  10                   10   \n",
            "\n",
            "   cholesterol_score  obesity_score  kidney_score  \n",
            "0                  9             10             9  \n",
            "1                  9              8             8  \n",
            "2                  9             10             9  \n",
            "3                  9              8             7  \n",
            "4                  9              8             9  \n",
            "\n",
            "======================================================================\n",
            "üîç EXPLORATORY DATA ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "üìä Dataset Info:\n",
            "----------------------------------------------------------------------\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 12 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   food_id              5000 non-null   int64 \n",
            " 1   food_name            5000 non-null   object\n",
            " 2   category             5000 non-null   object\n",
            " 3   calories             5000 non-null   int64 \n",
            " 4   protein              5000 non-null   int64 \n",
            " 5   carbohydrates        5000 non-null   int64 \n",
            " 6   diabetes_score       5000 non-null   int64 \n",
            " 7   hypertension_score   5000 non-null   int64 \n",
            " 8   heart_disease_score  5000 non-null   int64 \n",
            " 9   cholesterol_score    5000 non-null   int64 \n",
            " 10  obesity_score        5000 non-null   int64 \n",
            " 11  kidney_score         5000 non-null   int64 \n",
            "dtypes: int64(10), object(2)\n",
            "memory usage: 468.9+ KB\n",
            "None\n",
            "\n",
            "üìà Statistical Summary:\n",
            "----------------------------------------------------------------------\n",
            "           food_id     calories      protein  carbohydrates  diabetes_score  \\\n",
            "count  5000.000000  5000.000000  5000.000000    5000.000000     5000.000000   \n",
            "mean   2500.500000   233.208200    24.691400      23.826800        6.938000   \n",
            "std    1443.520003    63.374153    11.359682      15.346788        1.970617   \n",
            "min       1.000000   100.000000     5.000000       0.000000        1.000000   \n",
            "25%    1250.750000   199.000000    16.000000      12.000000        6.000000   \n",
            "50%    2500.500000   221.000000    23.000000      21.000000        7.000000   \n",
            "75%    3750.250000   267.000000    32.000000      33.000000        8.000000   \n",
            "max    5000.000000   480.000000    55.000000      70.000000       10.000000   \n",
            "\n",
            "       hypertension_score  heart_disease_score  cholesterol_score  \\\n",
            "count         5000.000000          5000.000000        5000.000000   \n",
            "mean             7.861000             8.259800           7.409200   \n",
            "std              1.662237             1.562175           1.333008   \n",
            "min              2.000000             2.000000           5.000000   \n",
            "25%              7.000000             7.000000           7.000000   \n",
            "50%              8.000000             9.000000           7.000000   \n",
            "75%              9.000000            10.000000           9.000000   \n",
            "max             10.000000            10.000000           9.000000   \n",
            "\n",
            "       obesity_score  kidney_score  \n",
            "count    5000.000000   5000.000000  \n",
            "mean        7.407600      6.466000  \n",
            "std         1.718503      2.036387  \n",
            "min         2.000000      1.000000  \n",
            "25%         6.000000      5.000000  \n",
            "50%         8.000000      7.000000  \n",
            "75%         8.000000      8.000000  \n",
            "max        10.000000     10.000000  \n",
            "\n",
            "‚úì No missing values found!\n",
            "\n",
            "üìä Category Distribution:\n",
            "category\n",
            "Salads & Greens      500\n",
            "Low-Carb Meals       500\n",
            "High-Protein         500\n",
            "Heart-Healthy        500\n",
            "Diabetic-Friendly    500\n",
            "Whole Grains         500\n",
            "Lean Protein         500\n",
            "Vegetarian           500\n",
            "Soups                500\n",
            "Grilled Items        500\n",
            "Name: count, dtype: int64\n",
            "\n",
            "üìä Creating visualizations...\n",
            "  ‚úì Saved: /content/drive/MyDrive/health_scores_distribution.png\n",
            "  ‚úì Saved: /content/drive/MyDrive/correlation_matrix.png\n",
            "  ‚úì Saved: /content/drive/MyDrive/category_distribution.png\n",
            "\n",
            "======================================================================\n",
            "‚öô DATA PREPROCESSING\n",
            "======================================================================\n",
            "\n",
            "‚úì Category encoding completed\n",
            "  - Categories: ['Diabetic-Friendly', 'Grilled Items', 'Heart-Healthy', 'High-Protein', 'Lean Protein', 'Low-Carb Meals', 'Salads & Greens', 'Soups', 'Vegetarian', 'Whole Grains']\n",
            "\n",
            "‚úì Binary labels created (threshold: 7)\n",
            "\n",
            "‚úì Features prepared:\n",
            "  - Feature shape: (5000, 4)\n",
            "  - Features: ['calories', 'protein', 'carbohydrates', 'category_encoded']\n",
            "\n",
            "‚úì Targets prepared:\n",
            "  - Target shape: (5000, 6)\n",
            "  - Targets: ['diabetes_suitable', 'hypertension_suitable', 'heart_disease_suitable', 'cholesterol_suitable', 'obesity_suitable', 'kidney_suitable']\n",
            "\n",
            "‚úì Data split completed:\n",
            "  - Training set: 4000 samples\n",
            "  - Testing set: 1000 samples\n",
            "\n",
            "‚úì Feature scaling completed\n",
            "\n",
            "======================================================================\n",
            "ü§ñ MODEL TRAINING\n",
            "======================================================================\n",
            "\n",
            "üîÑ Training Random Forest...\n",
            "  ‚úì Random Forest accuracy: 0.9980\n",
            "\n",
            "üîÑ Training Gradient Boosting...\n",
            "  ‚úì Gradient Boosting accuracy: 0.9940\n",
            "\n",
            "üîÑ Training Decision Tree...\n",
            "  ‚úì Decision Tree accuracy: 0.9960\n",
            "\n",
            "üèÜ Best Model: Random Forest\n",
            "  - Accuracy: 0.9980\n",
            "\n",
            "======================================================================\n",
            "üìä MODEL EVALUATION\n",
            "======================================================================\n",
            "\n",
            "üéØ Overall Accuracy: 0.9980\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Accuracy per Health Condition:\n",
            "----------------------------------------------------------------------\n",
            "  diabetes_suitable             : 1.0000\n",
            "  hypertension_suitable         : 1.0000\n",
            "  heart_disease_suitable        : 1.0000\n",
            "  cholesterol_suitable          : 1.0000\n",
            "  obesity_suitable              : 0.9980\n",
            "  kidney_suitable               : 1.0000\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Detailed Classification Reports:\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "diabetes_suitable:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Not Suitable       1.00      1.00      1.00       333\n",
            "    Suitable       1.00      1.00      1.00       667\n",
            "\n",
            "    accuracy                           1.00      1000\n",
            "   macro avg       1.00      1.00      1.00      1000\n",
            "weighted avg       1.00      1.00      1.00      1000\n",
            "\n",
            "\n",
            "hypertension_suitable:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Not Suitable       1.00      1.00      1.00       176\n",
            "    Suitable       1.00      1.00      1.00       824\n",
            "\n",
            "    accuracy                           1.00      1000\n",
            "   macro avg       1.00      1.00      1.00      1000\n",
            "weighted avg       1.00      1.00      1.00      1000\n",
            "\n",
            "\n",
            "heart_disease_suitable:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Not Suitable       1.00      1.00      1.00       123\n",
            "    Suitable       1.00      1.00      1.00       877\n",
            "\n",
            "    accuracy                           1.00      1000\n",
            "   macro avg       1.00      1.00      1.00      1000\n",
            "weighted avg       1.00      1.00      1.00      1000\n",
            "\n",
            "\n",
            "cholesterol_suitable:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Not Suitable       1.00      1.00      1.00       245\n",
            "    Suitable       1.00      1.00      1.00       755\n",
            "\n",
            "    accuracy                           1.00      1000\n",
            "   macro avg       1.00      1.00      1.00      1000\n",
            "weighted avg       1.00      1.00      1.00      1000\n",
            "\n",
            "\n",
            "obesity_suitable:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Not Suitable       1.00      0.99      1.00       283\n",
            "    Suitable       1.00      1.00      1.00       717\n",
            "\n",
            "    accuracy                           1.00      1000\n",
            "   macro avg       1.00      1.00      1.00      1000\n",
            "weighted avg       1.00      1.00      1.00      1000\n",
            "\n",
            "\n",
            "kidney_suitable:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Not Suitable       1.00      1.00      1.00       489\n",
            "    Suitable       1.00      1.00      1.00       511\n",
            "\n",
            "    accuracy                           1.00      1000\n",
            "   macro avg       1.00      1.00      1.00      1000\n",
            "weighted avg       1.00      1.00      1.00      1000\n",
            "\n",
            "\n",
            "üìä Creating feature importance visualization...\n",
            "  ‚úì Saved: /content/drive/MyDrive/feature_importance.png\n",
            "\n",
            "======================================================================\n",
            "üíæ SAVING MODELS\n",
            "======================================================================\n",
            "\n",
            "‚úì Models saved successfully!\n",
            "  - Model:   /content/drive/MyDrive/Olive-Foods-ML-models/food_recommendation_model.pkl\n",
            "  - Scaler:  /content/drive/MyDrive/Olive-Foods-ML-models/feature_scaler.pkl\n",
            "  - Features:/content/drive/MyDrive/Olive-Foods-ML-models/feature_columns.pkl\n",
            "\n",
            "üìÅ Models are in your Google Drive under:\n",
            "  My Drive / Olive-Foods-ML-models\n",
            "\n",
            "======================================================================\n",
            "üß™ TESTING PREDICTIONS\n",
            "======================================================================\n",
            "\n",
            "üçΩ  Grilled Chicken Salad\n",
            "  Nutritional Info: 250 cal, 35g protein, 15g carbs\n",
            "  Suitability:\n",
            "    diabetes_suitable             : ‚úì Suitable\n",
            "    hypertension_suitable         : ‚úì Suitable\n",
            "    heart_disease_suitable        : ‚úì Suitable\n",
            "    cholesterol_suitable          : ‚úó Not Suitable\n",
            "    obesity_suitable              : ‚úì Suitable\n",
            "    kidney_suitable               : ‚úó Not Suitable\n",
            "\n",
            "üçΩ  Fried Chicken Burger\n",
            "  Nutritional Info: 680 cal, 28g protein, 52g carbs\n",
            "  Suitability:\n",
            "    diabetes_suitable             : ‚úó Not Suitable\n",
            "    hypertension_suitable         : ‚úó Not Suitable\n",
            "    heart_disease_suitable        : ‚úó Not Suitable\n",
            "    cholesterol_suitable          : ‚úì Suitable\n",
            "    obesity_suitable              : ‚úó Not Suitable\n",
            "    kidney_suitable               : ‚úó Not Suitable\n",
            "\n",
            "üçΩ  Vegetable Soup\n",
            "  Nutritional Info: 120 cal, 5g protein, 18g carbs\n",
            "  Suitability:\n",
            "    diabetes_suitable             : ‚úì Suitable\n",
            "    hypertension_suitable         : ‚úì Suitable\n",
            "    heart_disease_suitable        : ‚úì Suitable\n",
            "    cholesterol_suitable          : ‚úì Suitable\n",
            "    obesity_suitable              : ‚úì Suitable\n",
            "    kidney_suitable               : ‚úì Suitable\n",
            "\n",
            "======================================================================\n",
            "‚úÖ MODEL TRAINING COMPLETED SUCCESSFULLY!\n",
            "======================================================================\n",
            "\n",
            "üì¶ Next Steps:\n",
            "  1. Download the .pkl files from your Google Drive\n",
            "  2. Place them in your Flask app's 'models' directory\n",
            "  3. Start your Flask ML service and connect it to your MERN backend\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "import joblib\n",
        "import warnings\n",
        "import os\n",
        "import sys\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Plot style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "# =====================================================================\n",
        "# GOOGLE COLAB SETUP\n",
        "# =====================================================================\n",
        "\n",
        "def setup_colab_environment():\n",
        "    \"\"\"\n",
        "    Detect if running in Google Colab and mount Google Drive.\n",
        "    Returns: (base_path, in_colab)\n",
        "        base_path: folder corresponding to 'My Drive'\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import google.colab\n",
        "        IN_COLAB = True\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üîó GOOGLE COLAB DETECTED\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        from google.colab import drive\n",
        "        print(\"\\nüìÅ Mounting Google Drive...\")\n",
        "        drive.mount('/content/drive')\n",
        "        print(\"‚úì Google Drive mounted successfully!\")\n",
        "\n",
        "        # Base path points to 'My Drive'\n",
        "        base_path = '/content/drive/MyDrive'\n",
        "        print(f\"‚úì Working base path (My Drive): {base_path}\")\n",
        "\n",
        "        return base_path, IN_COLAB\n",
        "\n",
        "    except ImportError:\n",
        "        # Not in Colab\n",
        "        print(\"\\nüíª Running locally\")\n",
        "        return '', False\n",
        "\n",
        "\n",
        "# Initialize environment (GLOBAL)\n",
        "BASE_PATH, IN_COLAB = setup_colab_environment()\n",
        "\n",
        "# Change this if your file is in a subfolder of My Drive\n",
        "DATASET_NAME = 'food_health_dataset.csv'  # Must exist under BASE_PATH\n",
        "\n",
        "\n",
        "class FoodRecommendationModel:\n",
        "    \"\"\"Food Recommendation ML Model Trainer\"\"\"\n",
        "\n",
        "    def __init__(self, dataset_path=DATASET_NAME):\n",
        "        \"\"\"Initialize the model trainer\"\"\"\n",
        "        self.dataset_path = dataset_path\n",
        "        self.df = None\n",
        "\n",
        "        self.feature_cols = None\n",
        "        self.target_cols = None\n",
        "\n",
        "        self.X_train = None\n",
        "        self.X_test = None\n",
        "        self.y_train = None\n",
        "        self.y_test = None\n",
        "\n",
        "        self.X_train_scaled = None\n",
        "        self.X_test_scaled = None\n",
        "\n",
        "        self.scaler = None\n",
        "        self.model = None\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load dataset from CSV file\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üìä LOADING DATASET\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        # Build full path\n",
        "        if os.path.isabs(self.dataset_path):\n",
        "            full_dataset_path = self.dataset_path\n",
        "        elif BASE_PATH:\n",
        "            full_dataset_path = os.path.join(BASE_PATH, self.dataset_path)\n",
        "        else:\n",
        "            full_dataset_path = self.dataset_path\n",
        "\n",
        "        try:\n",
        "            self.df = pd.read_csv(full_dataset_path)\n",
        "            print(f\"‚úì Dataset loaded successfully!\")\n",
        "            print(f\"  - Path: {full_dataset_path}\")\n",
        "            print(f\"  - Shape: {self.df.shape}\")\n",
        "            print(f\"  - Food items: {len(self.df)}\")\n",
        "            print(\"\\nüìã First few rows:\")\n",
        "            print(self.df.head())\n",
        "            return True\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(\"‚úó Error: Dataset file not found!\")\n",
        "            print(f\"  Looking for: {full_dataset_path}\")\n",
        "            if IN_COLAB:\n",
        "                print(\"\\nüí° Tip: Make sure this file is in your Google Drive:\")\n",
        "                print(f\"  My Drive / {self.dataset_path}\")\n",
        "            else:\n",
        "                print(f\"  Please make sure '{self.dataset_path}' exists in the current directory.\")\n",
        "            return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚úó Error loading dataset: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def explore_data(self):\n",
        "        \"\"\"Perform exploratory data analysis\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üîç EXPLORATORY DATA ANALYSIS\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        print(\"\\nüìä Dataset Info:\")\n",
        "        print(\"-\" * 70)\n",
        "        print(self.df.info())\n",
        "\n",
        "        print(\"\\nüìà Statistical Summary:\")\n",
        "        print(\"-\" * 70)\n",
        "        print(self.df.describe())\n",
        "\n",
        "        # Check for missing values\n",
        "        missing = self.df.isnull().sum()\n",
        "        if missing.any():\n",
        "            print(\"\\n‚ö† Missing Values:\")\n",
        "            print(missing[missing > 0])\n",
        "        else:\n",
        "            print(\"\\n‚úì No missing values found!\")\n",
        "\n",
        "        # Category distribution\n",
        "        if 'category' in self.df.columns:\n",
        "            print(\"\\nüìä Category Distribution:\")\n",
        "            print(self.df['category'].value_counts())\n",
        "        else:\n",
        "            print(\"\\n‚ö† 'category' column not found in dataset!\")\n",
        "\n",
        "        # Visualizations\n",
        "        self._create_visualizations()\n",
        "\n",
        "    def _create_visualizations(self):\n",
        "        \"\"\"Create data visualizations\"\"\"\n",
        "        print(\"\\nüìä Creating visualizations...\")\n",
        "\n",
        "        # 1. Distribution of health scores\n",
        "        score_cols = [\n",
        "            'diabetes_score', 'hypertension_score', 'heart_disease_score',\n",
        "            'cholesterol_score', 'obesity_score', 'kidney_score'\n",
        "        ]\n",
        "        titles = [\n",
        "            'Diabetes', 'Hypertension', 'Heart Disease',\n",
        "            'Cholesterol', 'Obesity', 'Kidney Disease'\n",
        "        ]\n",
        "\n",
        "        available_score_cols = [c for c in score_cols if c in self.df.columns]\n",
        "        if available_score_cols:\n",
        "            fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "            fig.suptitle('Distribution of Health Suitability Scores',\n",
        "                         fontsize=16, fontweight='bold')\n",
        "\n",
        "            for idx, (col, title) in enumerate(zip(score_cols, titles)):\n",
        "                if col not in self.df.columns:\n",
        "                    continue\n",
        "                row = idx // 3\n",
        "                col_idx = idx % 3\n",
        "                axes[row, col_idx].hist(\n",
        "                    self.df[col],\n",
        "                    bins=10,\n",
        "                    edgecolor='black',\n",
        "                    alpha=0.7,\n",
        "                    color='steelblue'\n",
        "                )\n",
        "                axes[row, col_idx].set_title(\n",
        "                    f'{title} Suitability Scores',\n",
        "                    fontweight='bold'\n",
        "                )\n",
        "                axes[row, col_idx].set_xlabel('Score (1-10)')\n",
        "                axes[row, col_idx].set_ylabel('Frequency')\n",
        "                axes[row, col_idx].grid(alpha=0.3)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            viz_path = os.path.join(\n",
        "                BASE_PATH if BASE_PATH else '.',\n",
        "                'health_scores_distribution.png'\n",
        "            )\n",
        "            plt.savefig(viz_path, dpi=300, bbox_inches='tight')\n",
        "            print(f\"  ‚úì Saved: {viz_path}\")\n",
        "            plt.close()\n",
        "\n",
        "        # 2. Correlation heatmap\n",
        "        correlation_cols = [c for c in ['calories', 'protein', 'carbohydrates']\n",
        "                            if c in self.df.columns]\n",
        "        if len(correlation_cols) >= 2:\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            correlation_matrix = self.df[correlation_cols].corr()\n",
        "            sns.heatmap(\n",
        "                correlation_matrix,\n",
        "                annot=True,\n",
        "                fmt='.2f',\n",
        "                cmap='coolwarm',\n",
        "                center=0,\n",
        "                square=True,\n",
        "                linewidths=1\n",
        "            )\n",
        "            plt.title('Correlation Matrix of Nutritional Features',\n",
        "                      fontsize=14, fontweight='bold', pad=20)\n",
        "            plt.tight_layout()\n",
        "            viz_path = os.path.join(\n",
        "                BASE_PATH if BASE_PATH else '.',\n",
        "                'correlation_matrix.png'\n",
        "            )\n",
        "            plt.savefig(viz_path, dpi=300, bbox_inches='tight')\n",
        "            print(f\"  ‚úì Saved: {viz_path}\")\n",
        "            plt.close()\n",
        "\n",
        "        # 3. Category distribution\n",
        "        if 'category' in self.df.columns:\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            category_counts = self.df['category'].value_counts()\n",
        "            plt.bar(\n",
        "                range(len(category_counts)),\n",
        "                category_counts.values,\n",
        "                color='steelblue'\n",
        "            )\n",
        "            plt.xlabel('Category', fontweight='bold')\n",
        "            plt.ylabel('Count', fontweight='bold')\n",
        "            plt.title('Food Items by Category',\n",
        "                      fontsize=14, fontweight='bold', pad=20)\n",
        "            plt.xticks(\n",
        "                range(len(category_counts)),\n",
        "                category_counts.index,\n",
        "                rotation=45,\n",
        "                ha='right'\n",
        "            )\n",
        "            plt.grid(axis='y', alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "            viz_path = os.path.join(\n",
        "                BASE_PATH if BASE_PATH else '.',\n",
        "                'category_distribution.png'\n",
        "            )\n",
        "            plt.savefig(viz_path, dpi=300, bbox_inches='tight')\n",
        "            print(f\"  ‚úì Saved: {viz_path}\")\n",
        "            plt.close()\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        \"\"\"Preprocess and prepare data for training\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"‚öô DATA PREPROCESSING\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        # Encode categorical variable\n",
        "        if 'category' not in self.df.columns:\n",
        "            raise ValueError(\"Dataset must contain a 'category' column.\")\n",
        "\n",
        "        label_encoder = LabelEncoder()\n",
        "        self.df['category_encoded'] = label_encoder.fit_transform(self.df['category'])\n",
        "        print(\"\\n‚úì Category encoding completed\")\n",
        "        print(f\"  - Categories: {list(label_encoder.classes_)}\")\n",
        "\n",
        "        # Create binary suitability labels (score >= 7 is suitable)\n",
        "        threshold = 7\n",
        "        score_label_pairs = [\n",
        "            ('diabetes_score', 'diabetes_suitable'),\n",
        "            ('hypertension_score', 'hypertension_suitable'),\n",
        "            ('heart_disease_score', 'heart_disease_suitable'),\n",
        "            ('cholesterol_score', 'cholesterol_suitable'),\n",
        "            ('obesity_score', 'obesity_suitable'),\n",
        "            ('kidney_score', 'kidney_suitable')\n",
        "        ]\n",
        "\n",
        "        for score_col, label_col in score_label_pairs:\n",
        "            if score_col not in self.df.columns:\n",
        "                raise ValueError(f\"Missing required column in dataset: {score_col}\")\n",
        "            self.df[label_col] = (self.df[score_col] >= threshold).astype(int)\n",
        "\n",
        "        print(f\"\\n‚úì Binary labels created (threshold: {threshold})\")\n",
        "\n",
        "        # Define feature and target columns\n",
        "        self.feature_cols = ['calories', 'protein', 'carbohydrates', 'category_encoded']\n",
        "        self.target_cols = [\n",
        "            'diabetes_suitable', 'hypertension_suitable',\n",
        "            'heart_disease_suitable', 'cholesterol_suitable',\n",
        "            'obesity_suitable', 'kidney_suitable'\n",
        "        ]\n",
        "\n",
        "        for col in self.feature_cols:\n",
        "            if col not in self.df.columns:\n",
        "                raise ValueError(f\"Missing feature column: {col}\")\n",
        "\n",
        "        X = self.df[self.feature_cols]\n",
        "        y = self.df[self.target_cols]\n",
        "\n",
        "        print(f\"\\n‚úì Features prepared:\")\n",
        "        print(f\"  - Feature shape: {X.shape}\")\n",
        "        print(f\"  - Features: {self.feature_cols}\")\n",
        "        print(f\"\\n‚úì Targets prepared:\")\n",
        "        print(f\"  - Target shape: {y.shape}\")\n",
        "        print(f\"  - Targets: {self.target_cols}\")\n",
        "\n",
        "        # Train-test split\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        print(f\"\\n‚úì Data split completed:\")\n",
        "        print(f\"  - Training set: {self.X_train.shape[0]} samples\")\n",
        "        print(f\"  - Testing set: {self.X_test.shape[0]} samples\")\n",
        "\n",
        "        # Feature scaling\n",
        "        self.scaler = StandardScaler()\n",
        "        self.X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
        "        self.X_test_scaled = self.scaler.transform(self.X_test)\n",
        "\n",
        "        print(f\"\\n‚úì Feature scaling completed\")\n",
        "\n",
        "    def train_models(self):\n",
        "        \"\"\"Train multiple ML models and select the best one\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"ü§ñ MODEL TRAINING\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        models = {\n",
        "            'Random Forest': RandomForestClassifier(\n",
        "                n_estimators=100,\n",
        "                random_state=42,\n",
        "                max_depth=10,\n",
        "                min_samples_split=5\n",
        "            ),\n",
        "            'Gradient Boosting': GradientBoostingClassifier(\n",
        "                n_estimators=100,\n",
        "                random_state=42,\n",
        "                max_depth=5,\n",
        "                learning_rate=0.1\n",
        "            ),\n",
        "            'Decision Tree': DecisionTreeClassifier(\n",
        "                random_state=42,\n",
        "                max_depth=8\n",
        "            )\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        for name, base_model in models.items():\n",
        "            print(f\"\\nüîÑ Training {name}...\")\n",
        "            model = MultiOutputClassifier(base_model)\n",
        "            model.fit(self.X_train_scaled, self.y_train)\n",
        "\n",
        "            y_pred = model.predict(self.X_test_scaled)\n",
        "            accuracy = accuracy_score(self.y_test, y_pred)\n",
        "\n",
        "            results[name] = {\n",
        "                'model': model,\n",
        "                'accuracy': accuracy,\n",
        "                'predictions': y_pred\n",
        "            }\n",
        "\n",
        "            print(f\"  ‚úì {name} accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        # Select best model\n",
        "        best_model_name = max(results, key=lambda x: results[x]['accuracy'])\n",
        "        self.model = results[best_model_name]['model']\n",
        "\n",
        "        print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
        "        print(f\"  - Accuracy: {results[best_model_name]['accuracy']:.4f}\")\n",
        "\n",
        "        return results, best_model_name\n",
        "\n",
        "    def evaluate_model(self):\n",
        "        \"\"\"Evaluate model performance\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üìä MODEL EVALUATION\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        y_pred = self.model.predict(self.X_test_scaled)\n",
        "        overall_accuracy = accuracy_score(self.y_test, y_pred)\n",
        "\n",
        "        print(f\"\\nüéØ Overall Accuracy: {overall_accuracy:.4f}\")\n",
        "        print(\"\\n\" + \"-\"*70)\n",
        "        print(\"Accuracy per Health Condition:\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        # Per-condition accuracy\n",
        "        for idx, condition in enumerate(self.target_cols):\n",
        "            acc = accuracy_score(self.y_test.iloc[:, idx], y_pred[:, idx])\n",
        "            print(f\"  {condition:30s}: {acc:.4f}\")\n",
        "\n",
        "        print(\"\\n\" + \"-\"*70)\n",
        "        print(\"Detailed Classification Reports:\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        for idx, condition in enumerate(self.target_cols):\n",
        "            print(f\"\\n{condition}:\")\n",
        "            print(\n",
        "                classification_report(\n",
        "                    self.y_test.iloc[:, idx],\n",
        "                    y_pred[:, idx],\n",
        "                    target_names=['Not Suitable', 'Suitable']\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Feature importance (RandomForest / Tree / GB)\n",
        "        if hasattr(self.model.estimators_[0], 'feature_importances_'):\n",
        "            self._plot_feature_importance()\n",
        "\n",
        "    def _plot_feature_importance(self):\n",
        "        \"\"\"Plot feature importance\"\"\"\n",
        "        print(\"\\nüìä Creating feature importance visualization...\")\n",
        "\n",
        "        importances = self.model.estimators_[0].feature_importances_\n",
        "        feature_importance_df = pd.DataFrame({\n",
        "            'feature': self.feature_cols,\n",
        "            'importance': importances\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.barh(\n",
        "            feature_importance_df['feature'],\n",
        "            feature_importance_df['importance'],\n",
        "            color='steelblue'\n",
        "        )\n",
        "        plt.xlabel('Importance', fontweight='bold')\n",
        "        plt.title('Feature Importance for Food Recommendations',\n",
        "                  fontsize=14, fontweight='bold', pad=20)\n",
        "        plt.grid(axis='x', alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        viz_path = os.path.join(\n",
        "            BASE_PATH if BASE_PATH else '.',\n",
        "            'feature_importance.png'\n",
        "        )\n",
        "        plt.savefig(viz_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"  ‚úì Saved: {viz_path}\")\n",
        "        plt.close()\n",
        "\n",
        "    def save_models(self, output_dir='models'):\n",
        "        \"\"\"Save trained models and preprocessing objects\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üíæ SAVING MODELS\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        # Adjust output directory for Colab\n",
        "        if IN_COLAB:\n",
        "            output_dir = os.path.join(BASE_PATH, output_dir)\n",
        "\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        model_path = os.path.join(output_dir, 'food_recommendation_model.pkl')\n",
        "        scaler_path = os.path.join(output_dir, 'feature_scaler.pkl')\n",
        "        features_path = os.path.join(output_dir, 'feature_columns.pkl')\n",
        "\n",
        "        joblib.dump(self.model, model_path)\n",
        "        joblib.dump(self.scaler, scaler_path)\n",
        "        joblib.dump(self.feature_cols, features_path)\n",
        "\n",
        "        print(f\"\\n‚úì Models saved successfully!\")\n",
        "        print(f\"  - Model:   {model_path}\")\n",
        "        print(f\"  - Scaler:  {scaler_path}\")\n",
        "        print(f\"  - Features:{features_path}\")\n",
        "\n",
        "        if IN_COLAB:\n",
        "            print(\"\\nüìÅ Models are in your Google Drive under:\")\n",
        "            print(f\"  My Drive / {os.path.relpath(output_dir, BASE_PATH)}\")\n",
        "\n",
        "    def test_prediction(self):\n",
        "        \"\"\"Test the model with sample predictions\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üß™ TESTING PREDICTIONS\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        # Example test cases (you can adjust categories according to your encoding)\n",
        "        test_foods = [\n",
        "            {\n",
        "                'name': 'Grilled Chicken Salad',\n",
        "                'calories': 250,\n",
        "                'protein': 35,\n",
        "                'carbohydrates': 15,\n",
        "                'category_encoded': 6  # Example code\n",
        "            },\n",
        "            {\n",
        "                'name': 'Fried Chicken Burger',\n",
        "                'calories': 680,\n",
        "                'protein': 28,\n",
        "                'carbohydrates': 52,\n",
        "                'category_encoded': 2\n",
        "            },\n",
        "            {\n",
        "                'name': 'Vegetable Soup',\n",
        "                'calories': 120,\n",
        "                'protein': 5,\n",
        "                'carbohydrates': 18,\n",
        "                'category_encoded': 8\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        for food in test_foods:\n",
        "            print(f\"\\nüçΩ  {food['name']}\")\n",
        "            print(f\"  Nutritional Info: {food['calories']} cal, \"\n",
        "                  f\"{food['protein']}g protein, \"\n",
        "                  f\"{food['carbohydrates']}g carbs\")\n",
        "\n",
        "            features = np.array([[\n",
        "                food['calories'],\n",
        "                food['protein'],\n",
        "                food['carbohydrates'],\n",
        "                food['category_encoded']\n",
        "            ]])\n",
        "\n",
        "            features_scaled = self.scaler.transform(features)\n",
        "            predictions = self.model.predict(features_scaled)[0]\n",
        "\n",
        "            print(\"  Suitability:\")\n",
        "            for idx, condition in enumerate(self.target_cols):\n",
        "                status = \"‚úì Suitable\" if predictions[idx] == 1 else \"‚úó Not Suitable\"\n",
        "                print(f\"    {condition:30s}: {status}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main training pipeline\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üçΩ  OLIVE FOODS - ML MODEL TRAINING\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nHealth-Based Food Recommendation System\")\n",
        "    print(\"Training machine learning model for personalized food recommendations\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    trainer = FoodRecommendationModel(dataset_path=DATASET_NAME)\n",
        "\n",
        "    # Load data\n",
        "    if not trainer.load_data():\n",
        "        print(\"\\n‚ùå Training aborted due to data loading error.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Explore data\n",
        "    trainer.explore_data()\n",
        "\n",
        "    # Preprocess data\n",
        "    trainer.preprocess_data()\n",
        "\n",
        "    # Train models\n",
        "    results, best_model = trainer.train_models()\n",
        "\n",
        "    # Evaluate model\n",
        "    trainer.evaluate_model()\n",
        "\n",
        "    # Save models\n",
        "    trainer.save_models(output_dir='Olive-Foods-ML-models')\n",
        "\n",
        "    # Test predictions\n",
        "    trainer.test_prediction()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"‚úÖ MODEL TRAINING COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nüì¶ Next Steps:\")\n",
        "    print(\"  1. Download the .pkl files from your Google Drive\")\n",
        "    print(\"  2. Place them in your Flask app's 'models' directory\")\n",
        "    print(\"  3. Start your Flask ML service and connect it to your MERN backend\")\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}